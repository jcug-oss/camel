[[jdbc-component]]
== JDBC コンポーネント

*Camel version 1.2 から利用可能*

*jdbc* コンポーネントは JDBC 経由でデータベースにアクセスでき, 
SQL のクエリ(SELECT)や操作(INSERT, UPDATE その他)は, メッセージボディで送信される.
このコンポーネントは, 標準 JDBC API を使用しており, 
spring-jdbc を使用している <<sql-component,SQL Component>> とは異なる.

Meven ユーザは `pom.xml` に, 次の依存性を追加する必要がある:

[source,xml]
----
<dependency>
    <groupId>org.apache.camel</groupId>
    <artifactId>camel-jdbc</artifactId>
    <version>x.x.x</version>
    <!-- use the same version as your Camel core version -->
</dependency>
----

このコンポーネントは, プロデューサのエンドポイントを定義するためにのみ使用可能であり,
`from()` 内で JDBC コンポーネントは使用できない.

=== URI 書式

[source,text]
----
jdbc:dataSourceName[?options]
----

このコンポーネントは, プロデューサエンドポイントのみをサポートする.

次の書式で, URI にクエリオプションを追加できる.
`?option=value&option=value&...`

=== オプション

// component options: START
JDBC コンポーネントは, 以下の 2 つのオプションをサポートする.



[width="100%",cols="2,5,^1,2",options="header"]
|===
| 名前 | 説明 | デフォルト値 | 型
| *dataSource* (producer) | レジストリから名前でデータソースを検索する代わりに, データソースのインスタンスを使用する. |  | DataSource
| *resolveProperty Placeholders* (advanced) | 開始時に, コンポーネントが自分自身のプロパティプレースホルダを解決すべきかを指定する. String 型のプロパティのみがプロパティプレースホルダに利用できる. | true | boolean
|===
// component options: END






// endpoint options: START
JDBC エンドポイントは, URI シンタックスを利用して設定される:

----
jdbc:dataSourceName
----

また、次のパスとクエリパラメータで設定される:

==== パスパラメータ (1 parameters):


[width="100%",cols="2,5,^1,2",options="header"]
|===
| 名前 | 説明 | デフォルト値 | 型
| *dataSourceName* | *必須* レジストリ内で検索するデータソースの名前. 名前がデータソースもしくはデフォルトの場合は, Camel はレジストリからデフォルトのデータソースを検索する. ただ 1 つのデータソースのインスタンスが見つかった場合は, そのデータソースが使用される. |  | String
|===


==== クエリパラメータ (13 parameters):


[width="100%",cols="2,5,^1,2",options="header"]
|===
| 名前 | 説明 | デフォルト値 | 型
| *allowNamedParameters* (producer) | クエリ内で名前付きパラメータの使用を許可するか否かを指定する. | true | boolean
| *outputClass* (producer) | outputType に SelectOne もしくは SelectList を指定した場合に, 変換のために完全なパッケージとクラス名を指定する. |  | String
| *outputType* (producer) | プロデューサが使用する出力を決定する. | SelectList | JdbcOutputType
| *parameters* (producer) | java.sql.Statement に対するオプションパラメータ. 例えば, maxRows, fetchSize など. |  | Map
| *readSize* (producer) | The default maximum number of rows that can be read by a polling query. The default value is 0. |  | int
| *resetAutoCommit* (producer) | Camel will set the autoCommit on the JDBC connection to be false, commit the change after executed the statement and reset the autoCommit flag of the connection at the end, if the resetAutoCommit is true. If the JDBC connection doesn't support to reset the autoCommit flag, you can set the resetAutoCommit flag to be false, and Camel will not try to reset the autoCommit flag. When used with XA transactions you most likely need to set it to false so that the transaction manager is in charge of committing this tx. | true | boolean
| *transacted* (producer) | Whether transactions are in use. | false | boolean
| *useGetBytesForBlob* (producer) | To read BLOB columns as bytes instead of string data. This may be needed for certain databases such as Oracle where you must read BLOB columns as bytes. | false | boolean
| *useHeadersAsParameters* (producer) | Set this option to true to use the prepareStatementStrategy with named parameters. This allows to define queries with named placeholders, and use headers with the dynamic values for the query placeholders. | false | boolean
| *useJDBC4ColumnNameAnd LabelSemantics* (producer) | Sets whether to use JDBC 4 or JDBC 3.0 or older semantic when retrieving column name. JDBC 4.0 uses columnLabel to get the column name where as JDBC 3.0 uses both columnName or columnLabel. Unfortunately JDBC drivers behave differently so you can use this option to work out issues around your JDBC driver if you get problem using this component This option is default true. | true | boolean
| *beanRowMapper* (advanced) | To use a custom org.apache.camel.component.jdbc.BeanRowMapper when using outputClass. The default implementation will lower case the row names and skip underscores, and dashes. For example CUST_ID is mapped as custId. |  | BeanRowMapper
| *prepareStatementStrategy* (advanced) | Allows to plugin to use a custom org.apache.camel.component.jdbc.JdbcPrepareStatementStrategy to control preparation of the query and prepared statement. |  | JdbcPrepareStatement Strategy
| *synchronous* (advanced) | Sets whether synchronous processing should be strictly used, or Camel is allowed to use asynchronous processing (if supported). | false | boolean
|===
// endpoint options: END

// spring-boot-auto-configure options: START
=== Spring Boot Auto-Configuration

Spring Boot を利用する場合は, 自動設定を有効にするために, 次の Maven 依存性を使用していることを確認すること:

[source,xml]
----
<dependency>
  <groupId>org.apache.camel</groupId>
  <artifactId>camel-jdbc-starter</artifactId>
  <version>x.x.x</version>
  <!-- use the same version as your Camel core version -->
</dependency>
----


このコンポーネントは, 以下の 3 つのオプションをサポートする.



[width="100%",cols="2,5,^1,2",options="header"]
|===
| 名前 | 説明 | デフォルト値 | 型
| *camel.component.jdbc.data-source* | レジストリから名前でデータソースを検索する代わりに使用するデータソースのインスタンス.オプションは javax.sql.DataSource 型である. |  | String
| *camel.component.jdbc.enabled* | jdbc コンポーネントを有効化する | true | Boolean
| *camel.component.jdbc.resolve-property-placeholders* | 起動時にコンポーネントが, プロパティプレースホルダを解決するか否かを決定する. String 型であるプロパティのみがプロパティプレースホルダを使用できる. | true | Boolean
|===
// spring-boot-auto-configure options: END

=== 結果

デフォルトでは, 結果は `ArrayList<HashMap<String, Object>>` として OUT ボディ内に設定されて返却される.
`List` オブジェクトは行のリストを含んでおり, `Map` はカラム名として `String` を保持した各行の値を含んでいる.
結果を制御するために, オプションの `outputType` が使用できる.

*注意:* このコンポーネントは, `Map` 内でキーとしてカラム名を返却するために `ResultSetMetaData` を取得する.

==== Message ヘッダ

[width="100%",cols="10%,90%",options="header",]
|===
|ヘッダ |説明

|`CamelJdbcRowCount` |クエリが `SELECT` だった場合に, OUT ヘッダのこの値に取得した行数が返却されるようにする.

|`CamelJdbcUpdateCount` |クエリが `UPDATE` だった場合に, OUT ヘッダこの値に更新した行数が返却されるようにする.

|`CamelGeneratedKeysRows` |*Camel 2.10:* 生成されたキーを含む行.

|`CamelGeneratedKeysRowCount` |*Camel 2.10:* 生成されたキーを含む行数.

|`CamelJdbcColumnNames` |*Camel 2.11.1:* `java.util.Set` 型で ResultSet 内にあるカラム名.

|`CamelJdbcParametes` |*Camel 2.12:* `useHeadersAsParameters` が有効だった場合に, 使用されているヘッダの `java.util.Map`.
|===

=== キーの生成

*Camel 2.10 から利用可能*

INSERT 文を使ってデータを挿入すると, RDBMS は自動生成されたキーをサポートする場合がある.
<<jdbc-component,JDBC>> プロデューサに, 自動生成されたキーをヘッダに設定して返却するように指定することが可能である. +
そのためには, ヘッダに `CamelRetrieveGeneratedKeys=true` を設定する.
この設定により, 自動生成されたキーは上記の表のキーと共にヘッダに設定されて返却される。

より詳細な情報は
https://svn.apache.org/repos/asf/camel/trunk/components/camel-jdbc/src/test/java/org/apache/camel/component/jdbc/JdbcGeneratedKeysTest.java[unit
test] を参照すること.

自動生成キーを使用することは, 名前付きパラメータと同時には機能しない.

=== 名前付きパラメータの使用

*Camel 2.12 から利用可能*

以下のルートでは, プロジェクトテーブルから全てのプロジェクトを取得して使用としている.
SQL クエリが, :?lic と :?min. の 2 つのパラメータを持っていることに注意すること. +
Camel はメッセージヘッダから, これらのパラメータを検索する. この例では, 名前付きパラメータのために
2 つの定数の値を 2 つのヘッダに設定していることに注意すること:

[source,java]
----
  from("direct:projects")
     .setHeader("lic", constant("ASF"))
     .setHeader("min", constant(123))
     .setBody("select * from projects where license = :?lic and id > :?min order by id")
     .to("jdbc:myDataSource?useHeadersAsParameters=true")
----

ヘッダの値を `java.util.Map` 内に保持することもできて, その場合はキー名を `CamelJdbcParameters` としてヘッダに格納すること.

=== サンプル

以下の例では, カスタマー表から行を取得している.

まず, `testdb` として Camel にデータソースを登録する:

それから SQL が実行されるように JDBC コンポーネントへのルートを定義する.
前の手順で, 登録した `testdb` データソースをどのように参照しているかに注意すること:

もしくは Spring のように, 以下のようにして `DataSource` を作成することも可能である:

エンドポイントを作成し, IN メッセージのボディに SQL クエリを追加して, exchange を送信する.
クエリの結果は OUT ボディに設定されて返却される:

ResultSet で行全体を扱うよりも, 1 行ずつ扱いたい場合は, Splitter EIP を使用する必要がある:

[source,java]
----
from("direct:hello")
// here we split the data from the testdb into new messages one by one
// so the mock endpoint will receive a message per row in the table
// the StreamList option allows to stream the result of the query without creating a List of rows
// and notice we also enable streaming mode on the splitter
.to("jdbc:testdb?outputType=StreamList")
  .split(body()).streaming()
  .to("mock:result");
----

=== サンプル - 毎分データベースをポーリングする

JDBC コンポーネントを使用してデータベースをポーリングしたい場合は, 
JDBC コンポーネントと <<timer-component,Timer>> や <<quartz-component,Quartz>> などのポーリングスケジューラと連結する必要がある.
以下の例では, 60 秒毎にデータベースからデータを取得している:

[source,java]
----
from("timer://foo?period=60000")
  .setBody(constant("select * from customer"))
  .to("jdbc:testdb")
  .to("activemq:queue:customers");
----

=== サンプル - データソース間でのデータ移動

データのクエリでよくあるユースケースは, データ処理を行って別のデータソースに移すことである (ETL 操作).
以下の例では, 新規顧客のレコードを 1 時間ごとに取得元テーブルから取得して, フィルタと変換を行い転送先テーブルに移している:

[source,java]
----
from("timer://MoveNewCustomersEveryHour?period=3600000")
    .setBody(constant("select * from customer where create_time > (sysdate-1/24)"))
    .to("jdbc:testdb")
    .split(body())
        .process(new MyCustomerProcessor()) //filter/transform results as needed
        .setBody(simple("insert into processed_customer values('${body[ID]}','${body[NAME]}')"))
        .to("jdbc:testdb");
----

